# Workflow: Logs Analyzer

## Descripci√≥n

Comando de Slack que analiza logs de BigQuery usando un LLM.

## Comando Slack

```
/logs <UUID> [fecha] [entorno]
```

**Par√°metros:**
- `UUID`: obligatorio - Identificador del workflow/proceso
- `fecha`: opcional - Formato yyyyMMdd (default: fecha actual del sistema)
- `entorno`: opcional - "sta" o "prod" (default: "sta")

## Flujo

1. Recibir comando desde Slack (webhook/slash command)
2. Parsear par√°metros y aplicar defaults
3. Construir y ejecutar query en BigQuery
4. Obtener logs en formato JSON
5. Construir prompt con logs
6. Llamar API de Google Gemini para an√°lisis
7. Extraer respuesta de Gemini
8. Responder a Slack con el an√°lisis

## BigQuery Configuration

### Entorno STA (default)
- PROJECT_ID: `mm-provision-osp-sta`
- DATASET: `provision_osp_sta_containers_logs`
- table_name: `stdout_${date}` (date en formato yyyyMMdd)

### Entorno PROD
- PROJECT_ID: `mm-provision-osp-prod`
- DATASET: `provision_osp_prod_containers_logs`
- table_name: `stdout_${date}` (date en formato yyyyMMdd)

### Query Template

```sql
SELECT
  timestamp,
  jsonPayload.metadata.workflowtype,
  jsonPayload.metadata.activitytype,
  jsonPayload.message,
  httpRequest.requestUrl,
  jsonPayload.requestBody.content AS request,
  jsonPayload.responseBody.content AS response,
  httpRequest.status
FROM
  `${PROJECT_ID}.${DATASET}.${table_name}`
WHERE
  jsonPayload.loggername != 'org.hibernate.SQL'
  AND ( jsonPayload.message LIKE '%${uuid}%'
    OR jsonPayload.metadata.workflowId LIKE '${uuid}%' )
ORDER BY
  timestamp ASC
```

**Variables a reemplazar:**
- `${PROJECT_ID}`
- `${DATASET}`
- `${table_name}`
- `${uuid}`

## LLM Analysis

### API de Google Gemini

**Endpoint:** `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent`
**M√©todo:** POST
**Auth:** API Key via query parameter `?key=GEMINI_API_KEY`
**Modelo:** `gemini-2.0-flash-exp`

**Configuraci√≥n:** Ver `GEMINI_API_KEY_SETUP.md` para obtener y configurar la API key

### Prompt Template

```
Analyze the following BigQuery logs from a provisioning workflow execution.

IMPORTANT: Structure your response with the analysis first, then separate each JSON with "###JSON###".

Format rules for ANALYSIS section:
- Use *bold*, _italic_ for emphasis where needed
- Emojis: üöÄ ‚úÖ ‚ùå ‚ö†Ô∏è üîç üìä

Structure EXACTLY:

*üöÄ SUMMARY*
Resume the execution status, process times and representative information

*üîç EXECUTION FLOW*
Structure references to external system calls, with exceptions and success messages if any

*üèóÔ∏è TMF ANALYSIS*
Analyze input JSON and describe hierarchy of TMF format items and accounts. Include graphical representation with hints of JSON structure intent

*‚ö†Ô∏è KENAN ANALYSIS*
Analyze Kenan multiple service invocations payloads and describe the accounts and elements being processed

###JSON###
*üìÑ TMF ORDER JSON*
{...complete TMF order JSON formatted and indented...}

###JSON###
*üìÑ KENAN REQUEST #n*
{...complete kenan request JSON formatted and indented...}

###JSON###
*üìÑ KENAN RESPONSE #n*
{...complete kenan response JSON formatted and indented...}

Repeat for each Kenan call. DO NOT use ```json tags, just output the raw JSON.

Follow a strict order of the sections, do not mix them.

Here are the logs:
{bigquery-logs}
```

**Placeholder:**
- `{bigquery-logs}`: Reemplazar con resultados de BigQuery en JSON

**Separador:** La respuesta se divide usando `###JSON###` para separar el an√°lisis de los JSONs individuales.

## Arquitectura del Workflow Final

El workflow consta de 15 nodos conectados en la siguiente secuencia:

1. **Webhook** - Recibe POST de Slack con comando `/logs`
2. **Respond to Webhook** - Responde inmediatamente a Slack (< 0.1s) con mensaje de procesamiento
3. **Parse Parameters** - Parsea UUID, fecha y entorno; aplica defaults y validaciones; genera nombre del canal
4. **Create Slack Channel** - Crea canal p√∫blico en Slack con nombre `logs-{uuid}-{fecha}-{entorno}`
5. **Check Channel Created** - Verifica si el canal fue creado o ya exist√≠a; obtiene channel_id
6. **Invite User to Channel** - Invita al usuario que ejecut√≥ el comando al canal
7. **Send Initial Message** - Env√≠a mensaje inicial al canal ("‚è≥ Analizando logs...")
8. **BigQuery** - Ejecuta query SQL contra BigQuery para recuperar logs
9. **Build Prompt** - Construye prompt para Gemini con los logs en formato JSON
10. **Call Gemini API** - Llama a API REST de Gemini con el prompt
11. **Extract Gemini Response** - Extrae respuesta y divide en secciones por separador `###JSON###`
12. **Prepare Slack Message** - Prepara bloques Slack con `rich_text_preformatted` para JSONs
13. **Split In Batches** - Procesa mensajes uno por uno para garantizar orden secuencial
14. **Wait** - A√±ade delay de 1 segundo entre mensajes
15. **Send to Slack** - Env√≠a mensaje al canal v√≠a HTTP Request ‚Üí Loop back to Split In Batches

**Flujo clave:**
- Webhook ‚Üí respuesta inmediata ‚Üí creaci√≥n de canal ‚Üí procesamiento as√≠ncrono ‚Üí env√≠o secuencial
- Sin timeouts (respuesta en < 0.1s)
- Cada an√°lisis se env√≠a a un canal dedicado creado autom√°ticamente
- Canal p√∫blico con nombre descriptivo: `logs-{uuid}-{fecha}-{entorno}`
- Usuario invitado autom√°ticamente al canal
- Orden garantizado con Split In Batches + Wait + loop
- JSONs con formato de extracto usando `rich_text_preformatted`
- Delays de 1 segundo entre mensajes

## Estado

- [x] Workflow implementado en n8n
- [x] Workflow exportado a `flow/logs-analyzer.json`
- [x] Credenciales de GCP/BigQuery configuradas (Service Account: n8n-bigquery-logs@mm-provision-osp-sta.iam.gserviceaccount.com)
- [x] Gemini API integrada directamente (gemini-2.0-flash-exp)
- [x] GEMINI_API_KEY configurada en docker-compose.yml
- [x] Workflow activado en n8n
- [x] Workflow probado end-to-end con √©xito (44 logs analizados, respuesta generada correctamente)
- [x] Configuraci√≥n de Slack Slash Command completada
- [x] ngrok configurado para webhook p√∫blico
- [x] Formato Slack Blocks con markdown implementado
- [x] Mensajes divididos en secciones con orden correcto
- [x] Manejo de l√≠mite de 3000 caracteres por bloque
- [x] Validaci√≥n de par√°metro fecha (yyyyMMdd)
- [x] Respuesta inmediata a webhook para evitar timeout

## Informaci√≥n del Workflow

**ID en n8n:** `pI5VIZDiGAataU0N`
**Versi√≥n:** 111 (actual)
**Webhook URL:** `http://localhost:5678/webhook/slack-logs`
**Archivo exportado:** `flow/logs-analyzer.json`

## Configuraci√≥n de Slack Slash Command

### 1. Crear Slack App

1. Accede a https://api.slack.com/apps
2. Click en "Create New App" ‚Üí "From scratch"
3. Nombre: "Logs Analyzer" (o el que prefieras)
4. Selecciona tu workspace
5. Click "Create App"

### 2. Crear Slash Command

1. En el men√∫ lateral, ve a "Slash Commands"
2. Click "Create New Command"
3. Configura:
   - **Command:** `/logs`
   - **Request URL:** `http://localhost:5678/webhook/slack-logs` (o tu URL p√∫blica)
   - **Short Description:** "Analyze BigQuery logs with AI"
   - **Usage Hint:** `<UUID> [fecha] [entorno]`
4. Click "Save"

### 3. Instalar App en Workspace

1. En el men√∫ lateral, ve a "Install App"
2. Click "Install to Workspace"
3. Autoriza los permisos
4. La app estar√° disponible en tu workspace

### 4. Usar URL P√∫blica (Producci√≥n)

Para producci√≥n, necesitas exponer tu n8n con una URL p√∫blica:

**Opci√≥n 1: ngrok (desarrollo/testing)**
```bash
ngrok http 5678
# Usa la URL https://xxxxx.ngrok.io/webhook/slack-logs
```

**Opci√≥n 2: Dominio propio**
- Configura un reverse proxy (nginx/caddy)
- Apunta a tu instancia de n8n
- Usa certificado SSL (Let's Encrypt)

### 5. Actualizar Request URL

Una vez tengas la URL p√∫blica:
1. Ve a tu Slack App ‚Üí Slash Commands
2. Edita el comando `/logs`
3. Actualiza Request URL con tu URL p√∫blica
4. Guarda los cambios

## Resumen de Configuraci√≥n Completada

‚úÖ **Workflow implementado y activo**
- ID: `pI5VIZDiGAataU0N`
- Estado: **ACTIVO**
- Versi√≥n: 111 (actual)
- Nodos: 15 (incluyendo creaci√≥n autom√°tica de canales)
- Webhook URL local: `http://localhost:5678/webhook/slack-logs`
- Webhook URL p√∫blico: `https://TU-SUBDOMINIO.ngrok-free.app/webhook/slack-logs` (requiere configurar ngrok)

‚úÖ **Credenciales BigQuery configuradas**
- Service Account: `n8n-bigquery-logs@mm-provision-osp-sta.iam.gserviceaccount.com`
- Project STA: `mm-provision-osp-sta`
- Project PROD: `mm-provision-osp-prod`

‚úÖ **Gemini API integrada**
- Modelo: gemini-2.0-flash-exp
- API Key configurada en docker-compose.yml
- Endpoint: `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent`

‚úÖ **Workflow probado exitosamente**
- Funcionalidad principal: An√°lisis de logs con Gemini
- Respuesta webhook: **< 0.1 segundos** (sin timeout!)
- Creaci√≥n autom√°tica de canales Slack dedicados
- Mensajes enviados secuencialmente con delays de 1s
- Formato JSON: `rich_text_preformatted` para mejor visualizaci√≥n
- An√°lisis dividido en secciones: Summary, Execution Flow, TMF Analysis, Kenan Analysis + JSONs individuales

## Problemas Resueltos

Durante el desarrollo se resolvieron los siguientes problemas:

### 1. Timeout de Slack (operation_timeout)
**Problema:** Slack tiene un timeout de 3 segundos, pero el workflow tarda 30+ segundos
**Soluci√≥n:** A√±adido nodo "Respond to Webhook" que responde inmediatamente con mensaje de procesamiento, mientras el an√°lisis contin√∫a en segundo plano

### 2. Mensajes en orden inverso
**Problema:** Los mensajes JSON llegaban antes que el an√°lisis
**Soluci√≥n:** Implementado sistema de delays progresivos (0s, 2s, 4s, 6s...) en el nodo "Send Slack Response"

### 3. JSON sin formato de c√≥digo
**Problema:** Los bloques JSON no se mostraban con formato de c√≥digo
**Soluci√≥n:** Actualizado prompt de Gemini para usar exactamente ` ```json ` en todos los bloques JSON

### 4. Tablas sin formato correcto
**Problema:** Las tablas perd√≠an el formato de alineaci√≥n
**Soluci√≥n:** Cambiado a bloques preformateados con ` ``` ` para preservar espaciado

### 5. Error invalid_blocks (l√≠mite 3000 caracteres)
**Problema:** Bloques de texto exced√≠an el l√≠mite de 3000 caracteres de Slack
**Soluci√≥n:** Implementado divisi√≥n autom√°tica de texto en chunks de 2900 caracteres m√°ximo

### 6. Error invalid_payload (async en expresiones)
**Problema:** n8n no puede ejecutar funciones async dentro de expresiones `={{ }}`
**Soluci√≥n:** Cambiado nodo "Send Slack Response" de HTTP Request a Code node con soporte nativo async/await

### 7. Error de validaci√≥n de fecha
**Problema:** Tabla `stdout_2025111` no encontrada (7 d√≠gitos en lugar de 8)
**Soluci√≥n:** A√±adida validaci√≥n regex `/^\d{8}$/` en formato yyyyMMdd, con default a fecha actual si es inv√°lida

### 8. Error $http is not defined (Code node)
**Problema:** Objeto `$http` no est√° disponible en nodos Code de n8n
**Soluci√≥n:** Dividido en dos nodos: "Prepare Slack Message" (Code) y "Send to Slack" (HTTP Request)

### 9. Timeout persistente - Webhook no respond√≠a r√°pido
**Problema:** n8n esperaba a que todo el workflow terminara antes de responder al webhook
**Soluci√≥n:** Reorganizada la estructura del flujo: Webhook ‚Üí Respond to Webhook ‚Üí Parse Parameters ‚Üí resto del flujo. Ahora responde en 0.039 segundos

### 10. Partici√≥n de mensajes JSON
**Problema:** Los bloques JSON se part√≠an por tama√±o, cortando el JSON a la mitad
**Soluci√≥n:** Implementada l√≥gica inteligente que respeta los bloques ` ```json ` y no los parte

### 11. Redise√±o de partici√≥n de mensajes y formato de extractos
**Problema:** Error `invalid_blocks` en Slack al enviar m√∫ltiples secciones con JSONs embebidos en markdown
**Soluci√≥n:**
- Cambiado separador de `###SECTION###` a `###JSON###`
- Primer mensaje: Todo el an√°lisis (Summary, Execution Flow, Actions Table, TMF Analysis, Kenan Analysis)
- Mensajes siguientes: Un mensaje por cada JSON (TMF Order, Kenan Request, Kenan Response)
- JSONs se env√≠an con bloques `rich_text` + `rich_text_preformatted` (formato de extracto de Slack)
- Eliminaci√≥n autom√°tica de marcadores ` ```json ` y ` ``` ` de la respuesta de Gemini
- Actualizado prompt de Gemini para generar estructura correcta
- Actualizado "Extract Gemini Response" para marcar secciones como an√°lisis o JSON
- Actualizado "Prepare Slack Message" para formatear correctamente cada tipo de secci√≥n

### 12. Orden de mensajes garantizado
**Problema:** Mensajes llegaban desordenados a Slack en algunas ocasiones
**Soluci√≥n:**
- Convertido "Send to Slack" de HTTP Request a Code node
- Implementado ordenamiento por `section_number` antes de enviar
- A√±adido delay de 2 segundos entre cada mensaje usando `await` y `setTimeout`
- Env√≠o secuencial con `fetch` + `await` para garantizar orden correcto

### 13. Code nodes sin acceso a fetch/https/require
**Problema:** Code nodes en n8n no tienen acceso a `fetch`, `https.request` o `require` debido al sandbox
**Soluci√≥n Final:**
- Cambiado a arquitectura con Split In Batches + Wait + HTTP Request
- Split In Batches procesa items uno por uno (batchSize: 1)
- Wait a√±ade delay de 1 segundo entre mensajes
- HTTP Request env√≠a a Slack v√≠a nodo nativo
- Loop back de "Send to Slack" a "Split In Batches" para procesar siguiente mensaje
- Orden garantizado por el procesamiento secuencial del loop

### 14. Mejora: Canales dedicados por an√°lisis
**Mejora implementada:** Creaci√≥n autom√°tica de canales Slack para cada an√°lisis
**Beneficios:**
- Canal dedicado con nombre descriptivo: `logs-{uuid}-{fecha}-{entorno}`
- Historial de an√°lisis organizado por canal
- Usuario invitado autom√°ticamente al canal
- Evita saturar un canal √∫nico con m√∫ltiples an√°lisis
- Permite compartir an√°lisis espec√≠ficos f√°cilmente
**Implementaci√≥n:**
- Nodo "Create Slack Channel" crea canal p√∫blico
- Nodo "Check Channel Created" verifica creaci√≥n o reutiliza si existe
- Nodo "Invite User to Channel" invita al usuario
- Nodo "Send Initial Message" env√≠a mensaje de procesamiento al canal
- Resto de mensajes se env√≠an al canal dedicado

## Configuraci√≥n Completada

Todos los pasos han sido completados exitosamente:

1. ‚úÖ Configurar credenciales de Google Service Account en n8n
2. ‚úÖ Integrar Gemini API
3. ‚úÖ Configurar GEMINI_API_KEY en docker-compose
4. ‚úÖ Activar workflow en n8n
5. ‚úÖ Probar workflow end-to-end
6. ‚úÖ Crear Slack App y configurar Slash Command `/logs`
7. ‚úÖ Exponer webhook con URL p√∫blica (ngrok)
8. ‚úÖ Actualizar Request URL en Slack App con la URL p√∫blica
9. ‚úÖ Implementar formato Slack Blocks con markdown
10. ‚úÖ Corregir orden de mensajes con delays progresivos
11. ‚úÖ Manejar l√≠mite de 3000 caracteres por bloque
12. ‚úÖ Validar formato de fecha yyyyMMdd
13. ‚úÖ Implementar respuesta inmediata para evitar timeout
14. ‚úÖ Solucionar limitaciones de Code nodes con Split In Batches + Wait + HTTP Request
15. ‚úÖ Formato de extracto JSON con `rich_text_preformatted`
16. ‚úÖ Creaci√≥n autom√°tica de canales Slack dedicados por an√°lisis
17. ‚úÖ Invitaci√≥n autom√°tica del usuario al canal creado
18. ‚úÖ Reutilizaci√≥n de canales existentes si el nombre coincide

## Uso del Comando

Para usar el comando `/logs` en Slack:

```
/logs <UUID> [fecha] [entorno]
```

**Ejemplos:**
```
/logs f3fed7f5-396f-43cc-9580-623f40ba48bc
/logs f3fed7f5-396f-43cc-9580-623f40ba48bc 20251113
/logs f3fed7f5-396f-43cc-9580-623f40ba48bc 20251113 sta
/logs db2fc3e1-56a0-42fe-853c-d3ba20875b5c 20251111 prod
```

**Resultado:**
- Respuesta inmediata al comando: "‚è≥ Analizando logs... Los resultados se publicar√°n en breve."
- Creaci√≥n autom√°tica de canal dedicado: `logs-{uuid}-{fecha}-{entorno}`
- Usuario invitado autom√°ticamente al canal
- An√°lisis completo enviado al canal en m√∫ltiples mensajes ordenados:
  1. **An√°lisis principal**: Resumen, flujo de ejecuci√≥n, an√°lisis TMF/Kenan
  2. **JSON del TMF Order**: Formato de extracto con sintaxis destacada
  3. **JSONs de Kenan**: Request y Response para cada llamada
